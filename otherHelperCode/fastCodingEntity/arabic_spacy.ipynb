{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run code for our data to gather the entity that really make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shaka Khan 7 17 PER\n",
      "الرئيس 0 6 PER\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "import spacy\n",
    "import xx_ent_wiki_sm\n",
    "import pickle\n",
    "\n",
    "nlp = xx_ent_wiki_sm.load()\n",
    "\n",
    "doc = nlp('Quem é Shaka Khan?')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "doc = nlp('الرئيس')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('الرئيس')\n",
    "len(doc.ents)\n",
    "\n",
    "# for ent in doc.ents:\n",
    "#     print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabiclist=[]\n",
    "with open(\"entity_vs_count.data\",\"rb\") as f:\n",
    "    arabiclist=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1264295"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arabiclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\".\n",
      "85409\n",
      "اي\n",
      "54202\n",
      "العام\n",
      "52437\n",
      "الرئيس\n",
      "46287\n",
      "غير\n",
      "45041\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for key,val in arabiclist:\n",
    "    if count<5:\n",
    "        count=count+1\n",
    "        print(key)\n",
    "        print(val)\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 processed\n",
      "20000 processed\n",
      "30000 processed\n",
      "40000 processed\n",
      "50000 processed\n",
      "60000 processed\n",
      "70000 processed\n",
      "80000 processed\n",
      "90000 processed\n",
      "100000 processed\n",
      "110000 processed\n",
      "120000 processed\n",
      "130000 processed\n",
      "140000 processed\n",
      "150000 processed\n",
      "160000 processed\n",
      "170000 processed\n",
      "180000 processed\n",
      "190000 processed\n",
      "200000 processed\n",
      "210000 processed\n",
      "220000 processed\n",
      "230000 processed\n",
      "240000 processed\n",
      "250000 processed\n",
      "260000 processed\n",
      "270000 processed\n",
      "280000 processed\n",
      "290000 processed\n",
      "300000 processed\n",
      "310000 processed\n",
      "320000 processed\n",
      "330000 processed\n",
      "340000 processed\n",
      "350000 processed\n",
      "360000 processed\n",
      "370000 processed\n",
      "380000 processed\n",
      "390000 processed\n",
      "400000 processed\n",
      "410000 processed\n",
      "420000 processed\n",
      "430000 processed\n",
      "440000 processed\n",
      "450000 processed\n",
      "460000 processed\n",
      "470000 processed\n",
      "480000 processed\n",
      "490000 processed\n",
      "500000 processed\n",
      "510000 processed\n",
      "520000 processed\n",
      "530000 processed\n",
      "540000 processed\n",
      "550000 processed\n",
      "560000 processed\n",
      "570000 processed\n",
      "580000 processed\n",
      "590000 processed\n",
      "600000 processed\n",
      "610000 processed\n",
      "620000 processed\n",
      "630000 processed\n",
      "640000 processed\n",
      "650000 processed\n",
      "660000 processed\n",
      "670000 processed\n",
      "680000 processed\n",
      "690000 processed\n",
      "700000 processed\n",
      "710000 processed\n",
      "720000 processed\n",
      "730000 processed\n",
      "740000 processed\n",
      "750000 processed\n",
      "760000 processed\n",
      "770000 processed\n",
      "780000 processed\n",
      "790000 processed\n",
      "800000 processed\n",
      "810000 processed\n",
      "820000 processed\n",
      "830000 processed\n",
      "840000 processed\n",
      "850000 processed\n",
      "860000 processed\n",
      "870000 processed\n",
      "880000 processed\n",
      "890000 processed\n",
      "900000 processed\n",
      "910000 processed\n",
      "920000 processed\n",
      "930000 processed\n",
      "940000 processed\n",
      "950000 processed\n",
      "960000 processed\n",
      "970000 processed\n",
      "980000 processed\n",
      "990000 processed\n",
      "1000000 processed\n",
      "1010000 processed\n",
      "1020000 processed\n",
      "1030000 processed\n",
      "1040000 processed\n",
      "1050000 processed\n",
      "1060000 processed\n",
      "1070000 processed\n",
      "1080000 processed\n",
      "1090000 processed\n",
      "1100000 processed\n",
      "1110000 processed\n",
      "1120000 processed\n",
      "1130000 processed\n",
      "1140000 processed\n",
      "1150000 processed\n",
      "1160000 processed\n",
      "1170000 processed\n",
      "1180000 processed\n",
      "1190000 processed\n",
      "1200000 processed\n",
      "1210000 processed\n",
      "1220000 processed\n",
      "1230000 processed\n",
      "1240000 processed\n",
      "1250000 processed\n",
      "1260000 processed\n",
      "CPU times: user 49min 36s, sys: 4min 31s, total: 54min 7s\n",
      "Wall time: 1h 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stuff_makesense=[]\n",
    "count=0\n",
    "for key,val in arabiclist:\n",
    "    count=count+1\n",
    "    if count%10000==0:\n",
    "        print(str(count),\"processed\")  \n",
    "    doc=nlp(key)\n",
    "    if(len(doc.ents)==0):\n",
    "        continue;\n",
    "    for ent in doc.ents:\n",
    "        stuff_makesense.append({ent.text:ent.label_})\n",
    "        #print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuff make sense:  537587\n",
      "all the nouns parsed in our arabic sentences:  1264295\n",
      "percentage:  42.52069335083979%\n"
     ]
    }
   ],
   "source": [
    "print(\"stuff make sense: \",len(stuff_makesense))\n",
    "print(\"all the nouns parsed in our arabic sentences: \",len(arabiclist))\n",
    "print(\"percentage: \",str(len(stuff_makesense)/len(arabiclist)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"stuff_makesense_spacy_ner\",'wb') as f:\n",
    "        pickle.dump(stuff_makesense,f,pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'لبنان': 'LOC'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff_makesense[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import time\n",
    "import pickle\n",
    "client=MongoClient()\n",
    "client=MongoClient('mongodb://server:29017/')\n",
    "db=client['eventData']\n",
    "table=db[\"spacyResult\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanliang/eventData/yan-virtualenv/document_cluster/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for dic in stuff_makesense:\n",
    "    for key,value in dic.items():\n",
    "        table.insert({\"word\":key,\"ner\":value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_makesense[0]\n",
    "test={'العام': 'PER'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "العام\n"
     ]
    }
   ],
   "source": [
    "for i in test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing for spacy for Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import xx_ent_wiki_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp=xx_ent_wiki_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1=nlp(\"ويصف المسؤولون الفوائد أو التخفيضات الضريبية الفيدرالية المعدة للطاقة المتجددة ـ وهي تلك التي أنهى الكونغرس مدتها ثم جددها لمرات عدة ـ بأنها بالغة الأهمية\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ويصف 0 4 LOC\n"
     ]
    }
   ],
   "source": [
    "for ent in doc1.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2=nlp(\"وحول منافسة مشروع مشروع توسعة واعادة تأهيل مجمع صالات الحج بمطار الملك عبد العزيز الدولي قال مسؤولي الطيران المدني «لقد تقدمت خمس مجموعات تحالفات من الشركات السعودية والعالمية بعروضها، ووقع الاختيار على مجموعة بن لادن السعودية المتضامنة مع شركة (AEROPORT DE PARIS) الفرنسية كصاحبة أفضل العروضة، إذا فازت بأعلى النقاط بعد تقييم العروض فنيا وماليا\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وحول 0 4 LOC\n",
      "AEROPORT 246 254 MISC\n"
     ]
    }
   ],
   "source": [
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc3=nlp(\"عام 2005 اتفق جون وزوجته بيفرلي على الطلاق بعد زواج استمر 28 عاما، انجبا خلاله ولدين\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ent in doc3.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc4=nlp(\"فأجاب «كنت معروفا في السابق كممثل كوميدي في المسرح والتلفزيون، لكن الانترنت أتاحت لي الانتشار حاليaا في أوساط الشباب الذين يدركون أن أغلبية الساسة عندنا فاسدون ويشكلون طبقة منغلقة على نفسها، مثل احدى الطوائف الاجتماعية الوراثية عند الهندوس، حيث التمييز الطبقي يبنى على أساس المنزلة أو الثروة»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "فأجاب 0 5 PER\n"
     ]
    }
   ],
   "source": [
    "for ent in doc4.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
